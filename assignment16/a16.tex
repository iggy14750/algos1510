\documentclass{article}
\author{Isaac B Goss\\ James Hahn\\ Jonathan Dyer}
\title{Assignment 16}
\date{Tues, 10 Oct 2017}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage[margin=0.8in]{geometry}
\usepackage{graphicx}

% ============ USED FOR OUR FORMAT ============
\newtheorem{thm}{Claim}
\providecommand{\prob}[1]{\section*{Problem #1}}
\providecommand{\soln}{\textbf{Solution: }}
\providecommand{\image}[1]{
    \begin{center}
        \includegraphics%[width=0.95\textwidth]
            {#1}
    \end{center}
}
\providecommand{\tightlist}{
    \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}
}

% ============ USED FOR CODE LISTINGS ============
\usepackage{listings}
\usepackage[usenames,dvipsnames,svgnames]{xcolor}
\definecolor{javagreen}{rgb}{0.25,0.5,0.35}
\lstset{
    basicstyle   = \footnotesize,
    commentstyle = \color{javagreen},
    frame        = single,
    language     = C,
    stringstyle  = \color{orange},
    numbers      = left,
    showstringspaces=false,
    deletekeywords = {len, max, format, min},
    morekeywords = {yield, function, then, do, to},
    keywordstyle = \color{blue},
    escapeinside={(*}{*)}
}


\begin{document}
\maketitle





\prob{1}
Show that if there is an $O\left(n^2\right)$ time algorithm for multiplying two n by n lower triangular matrices then there is an $O\left(n^2\right)$ time algorithm for multiplying two arbitrary n by n matrices.

\soln Similarly to the problem about matrix squaring (done in class), we can reduce the problem of arbitrary matrix multiplication to the problem of multiplying lower triangular matrices quite easily, demonstrated by using a function 'multLower(A,B)' to give code for a 'multArb(A,B)' function. Such code follows:

\begin{lstlisting}
  function multArb(A,B):
    let C = (*$\begin{smallmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & A & 0 \\  \end{smallmatrix}$*)
    let D = (*$\begin{smallmatrix} 0 & 0 & 0 \\ B & 0 & 0 \\ 0 & 0 & 0 \\  \end{smallmatrix}$*)

    then E = multLower(C,D) = (*$\begin{smallmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ AB & 0 & 0 \\  \end{smallmatrix}$*)

    output lowerLeft(E)   // i.e. row 3, col 1
\end{lstlisting}

It is clear that since the conversion from matrices A and B is just writing out two new $3n * 3n$ block matrices, this step can be completed in $O\left(n^2\right)$ time. Then our assumed function 'multLower(C,D)' also takes $O\left(n^2\right)$ time, and finally the conversion back to the solution is simply writing out a new $n * n$ matrix, so we have an overall $O\left(n^2\right)$ runtime for multiplying arbitrary matrices.
\end{document}
