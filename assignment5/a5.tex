\documentclass{article}
\author{Isaac B Goss\\ James Hahn\\ Jonathan Dyer}
\title{Assignment 4: Greedy Algorithms}
\date{Wednesday, September 13, 2017}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage[margin=0.8in]{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[usenames,dvipsnames,svgnames]{xcolor}

%\setlength{\parindent}{0pt}
\newtheorem{thm}{Claim}
\providecommand{\prob}[1]{\section*{Problem #1}}
\providecommand{\image}[1]{
    \begin{center}
        \includegraphics{#1}
    \end{center}
}


\begin{document}
\maketitle

    \prob{12}
	INPUT: Positive integers $r_1, \dots, r_n $, and $c_1, \dots, c_n$. \\
	OUTPUT: An $n \times n$ matrix A with 0/1 entries such that for all $i$ the sum of the $i$\textsuperscript{th} row in A is $r_i$ and the sum of
	the $i$\textsuperscript{th} column in A is $c_i$, if such a matrix exists. Consider the following greedy algorithm that constructs A row
	by row. Assume that the first $i - 1$ rows have been constructed. Let $a_j$ be the number of 1\textsc{\char13}s in the $j$\textsuperscript{th} column in
	the first $i - 1$ rows. Now the $r_i$ columns with the maximum $c_j - a_j$ are assigned 1\textsc{\char13}s in row $i$, and the rest of the columns
	are assigned 0\textsc{\char13}s. That is, the columns that still needs the most 1\textsc{\char13}s are given 1\textsc{\char13}s.
	
    \begin{thm}
        This algorithm, A, is indeed correct.
    \end{thm}
    
	\begin{proof}
	Assume for a contradiction there exists some input matrix $I$ such that $A(I)$ produces incorrect input.
	
	Let $A(I)$ = the greedy algorithm's output on input $I$.
	Let $OPT(I)$ = the optimal solution on input $I$ that agrees
	with $A(I)$ for the most number of steps (rows from the top).
 	
    Let $i$ be the first row which differs in Opt(I) from A(I).
    In this row will be some pair of entries which differ from A(I), such that one of them is 1 in Opt(I), but 0 in A(I) (call its column $j$), and one which is 0 in Opt(I), and 1 in A(I) (call its column $k$).
    This occurs in such pairs so that the row value doesn't change.
    Now, we are going to operate on this pair, but notice that one can perform the same all points of difference between row $i$ in A(I) and Opt(I).
    
    Let $r_x = c_x - a_x \forall x \in [n]$. That is, $r_x$ represents the checkers which remain to be placed in column $x$ from row $i$ on down.
    Now, we have that $r_j \leq r_k$, since $k$ was picked by A and $j$ was not.
    
    Then let's consider what remains to be placed after row $i$ in Opt(I).
    $r'_x = r_x - Opt(I)_{i, x}$.
    Notice now that $r'_j = r_j - 1$, and $r'_k = r_k - 0$. So,
    
    \begin{align*}
    r_j &\leq r_k\\
    r_j - 1 &< r_k\\
    r'_j &< r'_k
    \end{align*}
    
    Then to consider the rest of these columns.
    There are strictly more checkers to place in column $k$ than $j$.
    This means there \textbf{must} exist some later row (call it $p$) on which column $j$ is 0, and column $k$ is 1 [Consider $k$'s 1s as buckets and $j$'s 1s as balls, there must be an empty bucket].
    
    Now, we can construct Opt'(I), which is exactly like Opt(I), except that the entries $(i, j), (i, k), (p, j), (p, k)$ are inverted (1s to 0s and vice versa).
    Note, row $i$ now agrees with A(I) (recall that we can do this for all differences in this row between A(I) and Opt(I)), which is one more row than Opt(I).
    Further, Opt'(I) is correct.
    In each row and column, a 0 has been replaced with a 1, and vice versa, so that the rows and columns each sum to the same values in Opt(I).
    
    So, this construction is a contradiction on the definition of Opt(I).
    And for this reason, $A$ is correct.
    
%	$OPT(I)$ = 
%	$\begin{bmatrix}
%		\vdots \\
%		\dots & x_{j}y_{i} & \dots & x_{j+s}y_{i} & \dots \\
%		\dots & x_{j}y_{i+t} & \dots & x_{j+s}y_{i+t} & \dots \\
%		\vdots
%	\end{bmatrix}$
%	
%	$A(I)$ = \hspace{12pt}
%	$\begin{bmatrix}
%		\vdots \\
%		\dots & x_{j}y_{i} & \dots & x_{j+s}y_{i} & \dots \\
%		\dots & x_{j}y_{i+t} & \dots & x_{j+s}y_{i+t} & \dots \\
%		\vdots
%	\end{bmatrix} $
%
%	Let $x_jy_i$ = the first point of disagreement between $A(I)$ and $OPT(I)$\\
%	Since the value of $x_jy_i$ differs in both $A(I)$ and $OPT(I)$, they must hold opposite values; this introduces two cases:
%	\begin{enumerate}
%		\item $A_{x_{j}y_{i}}$ = 0, $A_{x_{j+s}y_{i}}$ = 1, $A_{x_{j}y_{i+t}}$ = 1, $A_{x_{j+s}y_{i+t}}$ = 0 to ensure $\sum_{a=0}^{n} x_ar_i = r_i$ and $\sum_{a=0}^{n} c_jy_a = c_j$
%		\item $A_{x_{j}y_{i}}$ = 1, $A_{x_{j+s}y_{i}}$ = 0, $A_{x_{j}y_{i+t}}$ = 0, $A_{x_{j+s}y_{i+t}}$ = 1 to ensure $\sum_{a=0}^{n} x_ar_i = r_i$ and $\sum_{a=0}^{n} c_jy_a = c_j$
%	\end{enumerate}
%	
%	In either case, if $OPT(I)$ disagrees with $A(I)$ at $x_jy_i$, its values must be flipped for all values in $A(I)$ in both cases
%	above.
%	
%	Let $OPT\textsc{\char13}(I)$ = $OPT(I)$ but with the values of $OPT_{x_jy_i}$, $OPT_{x_{j+s}y_i}$ , $OPT_{x_jy_{i+t}}$, and $OPT_{x_{j+s}y_{i+t}}$ flipped
%		
%	Due to this flip, we have successfully moved one step closer to $A(I)$. For the first case, the $i$\textsuperscript{th} row of $OPT\textsc{\char13}(I)$
%	sums to $r_i - 1 + 1 = r_i$, the $(i + t)$\textsuperscript{th} row sums to $r_{i+t} + 1 - 1 = r_{i+t}$, the $j$\textsuperscript{th} column sums to $c_j + 1 - 1 = c_j$ , and the $(j + s)$\textsuperscript{th} column sums to $c_{j+s} - 1 + 1 = c_{j+s}$. As one can see, the rows and columns sum to the same values.
%	
%	Clearly, the same sums will hold up in the second case as well; the only difference is the values are flipped.
%	
%	Therefore, $OPT\textsc{\char13}(I)$ has moved one step closer to $A(I)$ and the rows and columns sum up to the same value, so it is still optimal.
%	
%	This creates a contradiction of our initial assumption that input matrix $I$ produces incorrect input, so $A(I)$ is
%	indeed correct.
	\end{proof}

\end{document}
