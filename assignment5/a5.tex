\documentclass{article}
\author{Isaac B Goss\\ James Hahn\\ Jonathan Dyer}
\title{Assignment 4: Greedy Algorithms}
\date{Wednesday, September 13, 2017}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage[margin=0.8in]{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[usenames,dvipsnames,svgnames]{xcolor}

\setlength{\parindent}{0pt}
\newtheorem{thm}{Claim}
\providecommand{\prob}[1]{\section*{Problem #1}}
\providecommand{\image}[1]{
    \begin{center}
        \includegraphics{#1}
    \end{center}
}


\begin{document}
\maketitle

    \prob{12}
	INPUT: Positive integers $r_1$, . . . , $r_n$ and $c_1$, . . . , $c_n$. \\
	OUTPUT: An n by n matrix A with 0/1 entries such that for all $i$ the sum of the $i$\textsuperscript{th} row in A is $r_i$ and the sum of
	the $i$\textsuperscript{th} column in A is $c_i$, if such a matrix exists. Consider the following greedy algorithm that constructs A row
	by row. Assume that the first $i - 1$ rows have been constructed. Let $a_j$ be the number of 1\textsc{\char13}s in the $j$\textsuperscript{th} column in
	the first $i - 1$ rows. Now the $r_i$ columns with the maximum $c_j - a_j$ are assigned 1\textsc{\char13}s in row $i$, and the rest of the columns
	are assigned 0\textsc{\char13}s. That is, the columns that still needs the most 1\textsc{\char13}s are given 1\textsc{\char13}s.
	
	\begin{proof}
	Assume for a contradiction there exists some input matrix $I$ such that $A(I)$ produces incorrect input.
	
	Let $A(I)$ = the greedy algorithm's output on input $I$.
	Let $OPT(I)$ = the optimal solution on input $I$ that agrees
	with $A(I)$ for the most number of steps.
 	
	$OPT(I)$ = 
	$\begin{bmatrix}
		\vdots \\
		\dots & x_{j}y_{i} & \dots & x_{j+s}y_{i} & \dots \\
		\dots & x_{j}y_{i+t} & \dots & x_{j+s}y_{i+t} & \dots \\
		\vdots
	\end{bmatrix}$
	
	$A(I)$ = %\hspace{12}
	$\begin{bmatrix}
		\vdots \\
		\dots & x_{j}y_{i} & \dots & x_{j+s}y_{i} & \dots \\
		\dots & x_{j}y_{i+t} & \dots & x_{j+s}y_{i+t} & \dots \\
		\vdots
	\end{bmatrix} $

	Let $x_jy_i$ = the first point of disagreement between $A(I)$ and $OPT(I)$\\
	Since the value of $x_jy_i$ differs in both $A(I)$ and $OPT(I)$, they must hold opposite values; this introduces two cases:
	\begin{enumerate}
		\item $A_{x_{j}y_{i}}$ = 0, $A_{x_{j+s}y_{i}}$ = 1, $A_{x_{j}y_{i+t}}$ = 1, $A_{x_{j+s}y_{i+t}}$ = 0 to ensure $\sum_{a=0}^{n} x_ar_i = r_i$ and $\sum_{a=0}^{n} c_jy_a = c_j$
		\item $A_{x_{j}y_{i}}$ = 1, $A_{x_{j+s}y_{i}}$ = 0, $A_{x_{j}y_{i+t}}$ = 0, $A_{x_{j+s}y_{i+t}}$ = 1 to ensure $\sum_{a=0}^{n} x_ar_i = r_i$ and $\sum_{a=0}^{n} c_jy_a = c_j$
	\end{enumerate}
	
	In either case, if $OPT(I)$ disagrees with $A(I)$ at $x_jy_i$, its values must be flipped for all values in $A(I)$ in both cases
	above.
	
	Let $OPT\textsc{\char13}(I)$ = $OPT(I)$ but with the values of $OPT_{x_jy_i}$, $OPT_{x_{j+s}y_i}$ , $OPT_{x_jy_{i+t}}$, and $OPT_{x_{j+s}y_{i+t}}$ flipped
		
	Due to this flip, we have successfully moved one step closer to $A(I)$. For the first case, the $i$\textsuperscript{th} row of $OPT\textsc{\char13}(I)$
	sums to $r_i - 1 + 1 = r_i$, the $(i + t)$\textsuperscript{th} row sums to $r_{i+t} + 1 - 1 = r_{i+t}$, the $j$\textsuperscript{th} column sums to $c_j + 1 - 1 = c_j$ , and the $(j + s)$\textsuperscript{th} column sums to $c_{j+s} - 1 + 1 = c_{j+s}$. As one can see, the rows and columns sum to the same values.
	
	Clearly, the same sums will hold up in the second case as well; the only difference is the values are flipped.
	
	Therefore, $OPT\textsc{\char13}(I)$ has moved one step closer to $A(I)$ and the rows and columns sum up to the same value, so it is still optimal.
	
	This creates a contradiction of our initial assumption that input matrix $I$ produces incorrect input, so $A(I)$ is
	indeed correct.
	\end{proof}

\end{document}
