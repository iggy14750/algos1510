\documentclass[12pt]{article}
\special{papersize=3in,5in}

\usepackage{amssymb,amsmath}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\providecommand{\st}{\ \text{s.t.}\ }
\providecommand{\tightlist}{
    \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}
}
\providecommand{\reducible}[2]{
  \textbf{#1} $\leq$ \textbf{#2}
}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  escapeinside = {(*}{*)},
  mathescape
}


\pagestyle{empty}
\setlength{\parindent}{0in}
\begin{document}

\section{REDUCTIONS}
\begin{centering}\textbf{\reducible{Matrix Mult}{Lower Triang Matrix Mult}}\par\end{centering}
\begin{lstlisting}
function matrixMult(A, B):
    C = [[0, 0, 0],
         [B, 0, 0],
         [0, A, 0]]
    D = [[0, 0, 0],
         [B, 0, 0],
         [0, A, 0]]
    E = lowerTriangMult(C, D)
    return lower left(E)  //bottom-left entry is AB
\end{lstlisting}


\begin{centering}\textbf{\reducible{Matrix Mult}{Matrix Inverse}}\par\end{centering}
\begin{lstlisting}
function matrixMult(A, B):
    C = [[I, A, 0],
         [0, I, B],
         [0, 0, I]]
    /**
     * Note now that C' = C-inverse is
     * D = [[I, -A, AB],
     *      [0,  I, -B],
     *      [0,  0,  I]]
     * This will be the output of our function matrixInverse(C)
     */
    D = matrixInverse(C)
    return upper right(D)
\end{lstlisting}


\begin{centering}\textbf{\reducible{PolyMult}{PolySquare}}\par\end{centering}
Let $a$ and $b$ be polynomials.
We have that $(a+b)^2 = a^2 + 2ab + b^2$.
Or, $\displaystyle ab = \frac{(a+b)^2 - a^2 - b^2}{2}$.\\
\begin{lstlisting}
function PolyMult(A, B)
    AB = PolySquare(A + B)
    A2 = PolySquare(A)
    B2 = PolySquare(B)
    C = (AB - A2 - B2) / 2
    return C
\end{lstlisting}

\begin{centering}\textbf{\reducible{Sort N Numbers}{Min Steiner Tree}}\par\end{centering}
Just like what we did in class with reducing "The Traveling Salesman" to sorting.
Simply create a coordinate for each number $i$ to be sorted in the form $(i,i)$,
giving you an adjacency list input that looks like $(a,a),(b,b), \dots, (n,n)$.
Then you'll get a graph that has a line (fun fact, it's $y=x$) which will contain,
in order from the origin, the sorted doubles of the numbers we want.
Then just extract the x-coordinate of every pair and you're golden.


\begin{centering}\textbf{Graph Isomorphisms: \reducible{Directed}{Mixed}}\par\end{centering}
A directed graph is already technically a mixed graph,
so in your algorithm for directed graphs simply feed the assumed mixed graph algorithm your input.
Return the output.


\begin{centering}\textbf{Graph Isomorphisms: \reducible{Undirected}{Directed}}\par\end{centering}
Given an undirected graph, simply make a copy of it with all edges replaced by
directed edge pairs to/from the endpoints of each (originally) undirected edge.
Feed this new directed graph to the assumed directed graph alg, then return the output.

\begin{centering}\textbf{Graph Isomorphisms: \reducible{Mixed}{Undirected}}\par\end{centering}
In this one we've assumed an algo that checks isomorphisms of undirected graphs,
so the task is to convert a mixed graph into some number of undirected graphs that contain the same information.
This is easily achieved as follows:
\begin{itemize}
  \item First label the vertices in order, i.e. number them from $1,\dots,n$.
  \item Make one copy of the mixed graph with only edges where there were originally undirected edges in the mixed graph as well.
  \item Make another copy of the mixed graph with only edges where, in the original mixed graph, the lower-numbered endpoint had a directed edge $towards$ the higher-numbered endpoint.
  \item As above, but reversed (so the only edges here were originally directed edges from the higher endpoint to the lower endpoint).
\end{itemize}
Now do this process for both of the mixed graphs in question, say $F$ and $G$, and then feed the corresponding outputs into the assumed undirected algorithm. If they all check out, then $F$ and $G$ are isomorphic.


\begin{centering}\textbf{\reducible{Independent Set}{Clique}, and \reducible{Clique}{Independent Set}}\par\end{centering}
We define the complement of some graph $G$, labelled $G^C$ to be a graph such that
\begin{enumerate}
  \item $V(G) = V(G^C)$
  \item $uv \in E(G^C)$ iff $u,v \in V(G^C)$ and $uv \not\in E(G)$.
\end{enumerate}
An independent set of vertices are a subset of vertices which are all pairwise non-adjacent.
Likewise, a clique is a subset of vertices which are all pairwise adjacent.
In the complement of some graph, all independent sets become cliques, and vice versa.
Thus we have the following reductions:
\begin{lstlisting}
function IndependentSet(G, i)
    return Clique($G^C$, i)
\end{lstlisting}
\begin{lstlisting}
function Clique(G, i)
    return IndependentSet($G^C$, i)
\end{lstlisting}


\begin{centering}\textbf{\reducible{Independent Set}{Vertex Cover} and \reducible{Vertex Cover}{Independent Set}}\par\end{centering}
We can define a relationship between these two problems, by noting the following:
\begin{itemize}
  \item Define graph $G$ by its set of vertices and edges, as $G = (V,E)$.
  \item Note that if $L \subset V$ is an independent set, then for any two neighboring vertices $u$ and $v$, at most one of them is in $L$ or else it wouldn't be an independent set. So then at $least$ one of every pair of neighbors is in $M = V - L$. Thus every edge in $E$ has an endpoint in $M$, so $M$ is a vertex cover.
  \item Conversely, if $M \subset V$ is a vertex cover, then consider any two vertices $x$ and $y$ in $L = V - M$. These two points can't be neighbors, else $M$ wouldn't be a cover. Thus no two points in $L$ are adjacent, so it must be an independent set.
\end{itemize}
\begin{lstlisting}
function IndependentSet(G, k)
    return VertexCover(G, n - k)
\end{lstlisting}
\begin{lstlisting}
function VertexCover(G, k)
    return IndependentSet(G, n - k)
\end{lstlisting}

\begin{centering}\textbf{\reducible{CliqueOpt}{CliqueDecision}}\par\end{centering}
We can reduce the clique optimization problem to clique decision by simply checking every value of $k$,
beginning at $n = |G|$ and decrementing.
Follow this by a closure operation which removes all vertices with degree less than k-1,
so that only the clique is left.
\begin{lstlisting}
function maxClique(G)
    for i = |G| downto 1 do
        if cliqueDecision(G, i) then
            return i
    return 0

alg cliqueOpt(Graph G)
    for v $\in$ V(G) do
        if maxClique(G) == maxClique(G - v) then
            G = G - v
    output G
\end{lstlisting}

\begin{centering}\textbf{\reducible{CliqueDecision}{2Clique}}\par\end{centering}
We can show that 2Clique is NP-hard by reducing another known NP-hard problem (here cliqueDecision) to it.
That is, we must show that cliqueDecision $\leq$ 2Clique in polynomial time.
We do this by giving an algorithm for cliqueDecision that uses 2Clique:
\begin{lstlisting}
alg cliqueDecision(H,j)   // simply create a new graph which is two copies of the original
  let G = H + H           // if this new graph has two cliques of the desired size, then
  return 2Clique(G,j)     // clearly the original has one
\end{lstlisting}
Obviously, creating a new graph that is just two copies of the original graph H takes $O(n)$ time, which when added to our cliqueDecision algorithm results in a total runtime of $O(n + f(n))$, where $f(n)$ is the runtime of cliqueDecision.


\begin{centering}\textbf{\reducible{HamiltonianCycle}{DoubleFixedHamiltonianPath}}\par\end{centering}
\begin{lstlisting}
HamiltonianCycle(Graph G)
  choose any v (*$\in$*) G
  return DoubleFixedHamiltonianPath(G, v, v)
\end{lstlisting}

\begin{centering}\textbf{\reducible{DoubleFixedHamiltonianPath}{HamiltonianCycle}}\par\end{centering}
\begin{lstlisting}
DoubleFixedHamiltonianPath(G, s, t)
  let H = G + (s,t)             // add edge (s,t) to graph
  return HamiltonianCycle(H)    // see if that makes a cycle
\end{lstlisting}

\begin{centering}\textbf{\reducible{SingleFixedHamiltonianPath}{DoubleFixedHamiltonianPath}}\par\end{centering}
\begin{lstlisting}
SingleFixedHamiltonianPath(G, s)
  for vertex v (*$\in$*) G do
      if DoubleFixedHamiltonianPath(G, s, v) then
          return true
  return false
\end{lstlisting}

\begin{centering}\textbf{\reducible{DoubleFixedHamiltonianPath}{SingleFixedHamiltonianPath}}\par\end{centering}
\begin{lstlisting}
DoubleFixedHamiltonianPath(G, s, t)
  if not (SFHP(G, s) and SFHP(G, t)) then
      return false
  C = G
  for edge e (*$\in$*) E(G) do
      if SFHP(C - e, s) and SFHP(C - e, t) then
          C = C - e
  if degree(*$_C$*)(s) == degree(*$_C$*)(s) == 1 then
      return true
  else return false
\end{lstlisting}
At the end of this process if we've removed all unnecessary edges whilst ensuring that paths starting at each endpoint are
intact, then neither will be left with more than one incident edge.

\begin{centering}\textbf{\reducible{HamCycleOpt}{HamCycleDecision}}\par\end{centering}
\begin{lstlisting}
HamCycleOpt(Graph G)
    C = G
    for edge uv (*$\in$*) E(G) do
        if HamCycleDecision(C - uv) then    // this means there's still a HamCycle in the graph
            C = C - uv                      // so get rid of the unnecessary edge
    return C                                // what's left is the Hamiltonian Cycle
\end{lstlisting}


\begin{centering}\textbf{\reducible{Clique}{$\dfrac{3}{4}$Clique}}\par\end{centering}
Check Max's solutions.

\begin{centering}\textbf{\reducible{IndependentSet}{$\dfrac{3}{4}$IndependentSet}}\par\end{centering}
Check Max's solutions.


\begin{centering}\textbf{\reducible{Clique}{CliqueAndInd}}\par\end{centering}
\begin{lstlisting}
function Clique(Graph G, int k)
    let H = new independent set of k vertices
    if CliqueAndInd(G+H,k)  // if the known independent set plus G passes the AND test,
        return 1            // then G$\ni$(k-clique)
\end{lstlisting}


\begin{centering}\textbf{\reducible{Clique}{CliqueOrInd}}\par\end{centering}
We simply need to eliminate any independent set in G without compromising a possible clique.
The easiest way to do this is to simply add a new vertex and connect it to all vertices in G.
Then any clique will just be one vertex larger, which is of course fine since (k+1)-cliques of course contain k-cliques.
\begin{lstlisting}
function Clique(Graph G, int k)
    let H = G $\times$ v    // cross product of G and one vertex
    return CliqueOrInd(H, k)
\end{lstlisting}


\begin{centering}\textbf{$\dfrac{3}{4}$Clique AND $\dfrac{3}{4}$IndependentSet}\par\end{centering}
Polynomial time algorithm! (via Max)

\begin{centering}\textbf{\reducible{IndependentSet}{$\dfrac{3}{4}$Clique OR $\dfrac{3}{4}$IndependentSet}}\par\end{centering}
Check Max's solutions.

\begin{centering}\textbf{\reducible{CNF-SAT}{Linear Inequality}}\par\end{centering}
Create a set of inequalities S as follows:\\
\begin{itemize}
  \item For each variable $x_i$ in boolean formula F, create integer var $x_i$.
  \item Add inequalities $x_i \geq 0$ and $x_i \leq 1$ to make it either 0 or 1.
  \item For each disjunction make a sum: if literal is $x_i$, add $x_i$; if $\overline{x_i}$, add $(1-x_i)$. Require the sum to be at least 1.
  \item This set of inequalities S is satisfied iff F is satisfied.
\end{itemize}

\begin{centering}\textbf{\reducible{3-coloring}{CNF-SAT}}\par\end{centering}
\begin{itemize}
  \item For each vertex $x$ in $G$, create $x_{red}$, $x_{blue}$, and $x_{green}$.
  \item Exactly one of those must be true for each vertex $x$.
  \item For each neighbor $y$ of $x$, we must have ($x_{color} \lor y_{color}$).
  \item Just "and" together all vertex clauses constructed above.
\end{itemize}

\begin{centering}\textbf{\reducible{Vertex Cover}{Dominating Set}}\par\end{centering}
Note: 'dominating set' = set S s.t. every vertex $v \in G$ is either in S or adjacent to S.
\begin{itemize}
  \item Make $G'$ by replacing each edge $e = (x,y)$ in $G$ by new vertex $v_e$ and edges $(x,v_e),(y,v_e),$ and $(x,y)$.
  \item Note: the vertex $v_e$ forces edge $e$ to be covered by a dominating set.
  \item Get minimum dominating set, call it $D$. If any $v_e \in D$, replace $v_e$ by $x$ (or $y$). Call this new set $D'$.
  \item Note that $D'$ is still dominating in $G'$, therefore we have a minimum cardinality vertex cover.
\end{itemize}


\begin{centering}\textbf{\reducible{IndependentSet}{TriadFree}}\par\end{centering}
????


\begin{centering}\textbf{\reducible{3Color}{Planar3Color}}\par\end{centering}
????


\begin{centering}\textbf{\reducible{VertexCover}{StrangeSubsetTraverse}}\par\end{centering}
????


\begin{centering}\textbf{\reducible{3SAT}{DisjointPaths}}\par\end{centering}
????


\begin{centering}\textbf{\reducible{3SAT}{TriangleProblem}}\par\end{centering}
????



\begin{centering}\textbf{\reducible{TriangleProblem}{DrCuddyDiseases}}\par\end{centering}
All triangles become tests.
"Minimum Test Collection Problem"


\begin{centering}\textbf{\reducible{VertexCover}{Fox,Goose,BoB}}\par\end{centering}
????





\section{PARALLEL ALGORITHMS}
\begin{centering}\textbf{AND of $n$ bits}\par\end{centering}
\subsubsection*{AND -- O(lg(n)), n procs, EREW}
\begin{itemize}\tightlist
  \item Recurse, halving the input size every time (AND-ing pairs of bits)
  \item This way it takes lg(height of call tree) = lg(n) constant time activations
  \item $E(n,n) = \frac{1}{lg(n)}$
\end{itemize}
\subsubsection*{AND -- O(lg(n)), n/lg(n) procs, EREW}
\begin{itemize}\tightlist
  \item Start by AND-ing lg(n) bits with each processor
  \item Recurse, halving the results every time (AND-ing pairs of bits)
  \item This way it takes lg(height of call tree) = lg($\frac{n}{lg(n)}$) constant time activations
  \item $T(n) = \theta(lg(n))$ | $E(n,n) = 1$
\end{itemize}\tightlist
\subsubsection*{AND -- O(1), n procs, CRCW Common}
\begin{lstlisting}
parFor each processor $p_i$ (pointing to unique bit)
    if bit $i$ == 0, then RESULT = FALSE
\end{lstlisting}


\begin{centering}\textbf{\reducible{Boolean Formula Value}{New Problem N}}\par\end{centering}
Write an alg $A$ for the boolean formula value problem that:\\
\begin{enumerate}\tightlist
  \item Only lacks code for problem N
  \item Runs in poly-log time w/ a poly \# of procs
\end{enumerate}
Then you'd have it...


\begin{centering}\textbf{ARRAY of $n$ ints}\par\end{centering}
\subsubsection*{ARRAY -- O(lg(n)), n procs, EREW}
\begin{lstlisting}
ARR($A[1] \dots A[n], x, p$)
  if p == 1 then $A[1] = x$
  else (*\(
        \left \{
            \begin{tabular}{l}
            ARR($A[1] \dots A[\frac{n}{2}], x, \frac{p}{2}$) \\
            ARR($A[\frac{n}{2}+1] \dots A[n], x, \frac{p}{2}$)
            \end{tabular}
        \right \}
        \)*)
\end{lstlisting}
$E(n,n) = \frac{1}{lg(n)}$
\subsubsection*{ARRAY -- O(lg(n)), n/lg(n) procs, EREW}
\begin{lstlisting}
logARR($A[1] \dots A[n], x, p$)
  if p == 1 then SequentialARR($A[1] \dots A[n]$)
  else (*\(
        \left \{
            \begin{tabular}{l}
            logARR($A[1] \dots A[\frac{n}{2}], x, \frac{p}{2}$) \\
            logARR($A[\frac{n}{2}+1] \dots A[n], x, \frac{p}{2}$)
            \end{tabular}
        \right \}
        \)*)
\end{lstlisting}
$T(n) = \theta(lg(n))$ | $E(n,n) = 1$
\subsubsection*{ARRAY -- O(1), n procs, CRCW Common}
Concurrently read $x$ with each processor, then concurrently write $x$ into $A[i]$ for each $i \in [n]$.\\
$E(n,p) = E(n,n) = \frac{n}{n*1} = 1$


\begin{centering}\textbf{ParPrefix -- O(lg(n)), n/lg(n) procs, EREW}\par\end{centering}
\begin{lstlisting}
function ParPrefix($x_1, x_2, \dots, x_n$, p)
    if p == 1 then
        return SeqPrefix($x_1, x_2, \dots, x_n$)
    else
        A = new int[n]
        C = ParPrefix($x_2, x_4, \dots, x_n$, p/2) // Assume n to be even WLOG
        B = ParPrefix($x_1, x_3, \dots, x_{n-1}$, p/2)
        parFor i = 1 to n do
            A[i] = B[ceil(i/2)] + C[floor(i/2)]
        return A
\end{lstlisting}



\begin{centering}\textbf{$n$ factorial -- O(lg(n)), n procs, EREW}\par\end{centering}
\begin{lstlisting}
fact($k, n, p$)   // k is the starting value for our partial product
    if k == n then return k
    else return fact($k, \frac{n+k}{2}, \frac{p}{2}$) $\times$ fact($\frac{n+k}{2}, n, \frac{p}{2}$)
\end{lstlisting}



\begin{centering}\textbf{MatMult of 2 $n\times n$ matrices}\par\end{centering}
\subsubsection*{MatMult -- O(n), $n^2$ procs, CREW}
\begin{lstlisting}
each processor $C_{ij}$ does (simultaneously):
    read row $i$ from matrix $A$      // n ops
    read column $j$ from matrix $B$   // n ops
    write $C_{ij} = A_i * B_j$        // dot product of two vectors; n + n ops
\end{lstlisting}
\subsubsection*{MatMult -- O(lg(n)), $n^3$ procs, CREW}
Use $n$ procs per entry $C_{i,j}$.
Compute the $n$ products $A_{i,k}B{k.j}, k\in [n]$ in constant time.
In lg(n) time do the sum $\sum_{k=1}^n A_{i,k}B_{k.j}$.
\subsubsection*{MatMult -- O(lg(n)), $n^3$/lg(n) procs, CRCW Common}
Each of the $n^2$ entries of C are done in parallel using $\frac{n}{lg(n)}$ procs.
Each proc does a sum of lg(n) products $\sum_{k=a}^b A_{i,k}B_{k,j}$ in lg(n) time.
Then sum those sums as $C_{i,j}$.
\subsubsection*{MatMult -- O(lg(n)), $n^3$/lg(n) procs, EREW}
Same as CRCW alg but first use $\frac{n}{lg(n)}$ procs per A and B entry to make $n$ copies of A and B in lg(n) time.
Then there are unique entries to read from.



\begin{centering}\textbf{Polynomial $p(x)$, compute $p(k)$ -- O(lg(n)), n procs, EREW}\par\end{centering}
In lg(n) time get $1,k,k^2,\dots ,k^n$. Then multiply coefficients in constant time.
Finally sum the terms in lg(n) time as usual (associative).


\begin{centering}\textbf{Prefix-Suffix -- poly-log, poly procs, EREW}\par\end{centering}
\begin{itemize}\tightlist
  \item Take $n^2$ procs, $n$ for each letter. Copy the entire input $n$ times in lg(n) time.
  \item Each of these copies goes with a $k$ from 1 to $n-1$ and gets $n$ procs.
  \item Each copy checks if it has a pref-suf match of length $k$; each proc checks a char (some do nothing) and gets a 1 if matched, 0 otherwise.
  \item Now AND the first and last $k$ bits for each copy in lg(n) time.
  \item Now run the standard parallel MAX alg (replacing 1's with $k$'s) in lg(n) time with $n$ procs.
\end{itemize}


\begin{centering}\textbf{Prefix-Suffix -- constant, poly procs, CRCW Common}\par\end{centering}
Same as EREW version with following changes:\\
\begin{itemize}\tightlist
  \item CR means we don't need to copy.
  \item Still consider each $k$ from $1 \dots n-1$ but read from same chars; still get $n$ bits for each group of $n$ procs.
  \item AND these using constant time CRCW AND alg. Now we need the maximum.
  \item Replace 1's with $k$'s (constant time). For each $k$ value (with $n$ procs), a proc looks at its own $k$ and one other group's $k$--it then writes $k$ to its output then checks its assigned other group. If the other $k$ is bigger, it writes 0 to its output. At this point only one of the possible "max-k's" should have a value other than 0. Find it.
\end{itemize}
\begin{lstlisting}
function PrefixSuffix(C)
    Have $O(n^2)$ processors consider all prefixes of C,
        one processor for each character of each prefix.
    let Ans = boolean array of length n initialized to all ones.
    For each prefix of length k do
        For each processor at position p do
            If C[p] $\ne$ C[n-k+p] then
                Ans[k] = 0
    output the maximum m such that Ans[m] = 1
\end{lstlisting}


\begin{centering}\textbf{ADD 2 $n$-bit ints}\par\end{centering}
\subsubsection*{ADD -- O(lg(n)), n procs, CREW}
\begin{itemize}\tightlist
  \item Calculate Generates (T[i]=1), Halts (T[i]=0), and Propagates (T[i]=-1).
  \item To convert to Carries, do (T[i]==1 $\rightarrow$ C[i]=1), (T[i]==0 $\rightarrow$ C[i]=0), else (C[i]=C[i-1]).
  This is done via Parallel Prefix (since it's associative) in lg(n).
  \item Sum[i] = C[i] XOR A[i] XOR B[i]   // constant time
\end{itemize}
\subsubsection*{ADD -- O(lg$^2$(n)), n procs, EREW}
????


\begin{centering}\textbf{AllPairsShortestPath -- O(lg$^2$(n)), $n^3$ procs, CREW (from class) into EREW}\par\end{centering}
The innermost loop can be $O(\lg n)$ time by introducing a new array, T.
This holds the weights of all alternative paths, and the minimum of such a list can be taken in parallel log time.
\begin{lstlisting}
T = new int[n]
parFor k = 1 to n do
    T[k] = A[i, k] + A[k, j]
    A[i, j] = min(A[i, j], ParMin(T, p = n))
\end{lstlisting}

\begin{centering}\textbf{AllPairsShortestPath, return paths -- O(lg$^2$(n)), $n^3$ procs, EREW}\par\end{centering}
Introduce \textbf{another} new matrix, P, which holds the actual path from each pair of vertices.
We shall also modify the usual parallel minimum function to create \texttt{ParMinI} which returns the \textbf{index} of the minimum element in an array, rather than the value itself.
\begin{lstlisting}
T = new int[n]
parFor k = 1 to n do
    T[k] = A[i, k] + A[k, j]
l = ParMinI(T, p = n)
if T[l] < A[i, j] then
    P[i, j] = P[i, l] + P[l, j]
A[i, j] = T[l]
\end{lstlisting}


\begin{centering}\textbf{Min Edit Distance -- poly-log, poly procs, CREW}\par\end{centering}
\begin{itemize}\tightlist
  \item Construct an $n\times n$ graph/matrix M with [i,j] indicating row A[i] and col B[j].
  \item Processor $p_{i,j}$ looks at A[i] and B[j]:\\
    -  If they match, make an edge from M[i,j] to M[i+1,j+1] of cost 0.\\
    -  If not,
    \begin{itemize}\tightlist
      \item Make edge M[i,j] to M[i+1,j] of cost 3
      \item Make edge M[i,j] to M[i,j+1] of cost 4
      \item Make edge M[i,j] to M[i+1,j+1] of cost 5
    \end{itemize}
  \item Final row/column is cost 4/3.
  \item Run AllPairsShortestPath, look up shortest path from [1,1] to [n+1,n+1].
  \item Takes time O(lg$^2$(n)) with O($n^2$) procs
\end{itemize}


\begin{centering}\textbf{MERGE 2 sorted arrays -- O(1), poly procs, CRCW Common}\par\end{centering}
  \begin{itemize}
    \item Divide into L and R arrays, then give $n$ procs to each $l_k$ we're trying to find the position of.
    \item Compare every $r_i$ to $l_k$ (in parallel) and check if $r_i > l_k$.
    \item If so, send a message to the processor to the left (checking $r_{i-1}$ with $l_k$).
    \item Only one proc will both not send such a message and receive one, and that's the rightmost $r$ left of $l_k$.
    \item Add the index of that and $l_k$ and you've got your final spot.
\end{itemize}


\begin{centering}\textbf{MAX of $n$ ints -- O(lg(lg(n))), n procs, CRCW Common}\par\end{centering}
Simply divide into $\sqrt{n}$ subproblems of size $\sqrt{n}$ each. Recurse on these, and note that with $n$ procs
we can compute the max of $\sqrt{n}$ elements in constant time using our standard

\begin{centering}\textbf{MAX of $n$ ints $\leq n$ -- O(1), n procs, CRCW Priority}\par\end{centering}
\begin{lstlisting}
function MAX($x_1, \dots, x_n$):
    T = new int[n]
    int max
    parFor i = 1 to n do
        // each processor puts a 1 in T, indexed by $x$-value
        arbitrarily assign procs $p_1 \dots p_n$ to the inputs, one each
        T[$x_i$] = 1
    parFor i = n to 1 do
        // now assign procs to cells in T in reverse order
        $p_i$ is assigned to T[n-i+1]
        if T[i] == 1 then
            max = T[i]    // highest priority proc with a '1' will be at index of max
    return max            // so that's the value that will get written
\end{lstlisting}

\begin{centering}\textbf{MAX of $n$ ints $\leq n$ -- O(1), n procs, CRCW Common}\par\end{centering}
\begin{itemize}
  \item Write a 1 to A[$x_i$] for each number
  \item Write a 1 to array R of length $\sqrt{n}$ in slot R[i] if there is a 1 anywhere in the i$^{th}$ $\sqrt{n}$-sized segment of A.
  \item Perform a "max" on the indices of R (find the largest index with a 1) in constant time (sqrt-sized, n procs)
  \item Perform an actual MAX on the sqrt-sized chunk of A that we just identified, also in constant time
\end{itemize}


\begin{centering}\textbf{COMPOSE arrays -- O(lg$^2$(n)), n procs, EREW}\par\end{centering}
\begin{itemize}\tightlist
  \item The major issue in this case is avoiding concurrent reads, which happens when two places in B are equal.
  \item What we're going to do to prevent that is to ``collect`` all processors trying to write the same value.
  \item This is done by dividing the B-space (domain) in binary fashion, keeping all procs with value above/below the midpoint in their respective bins.
  \item We will then implement a log-time copy operation, such that the value is first written to two of the positions in C.
  \item Then, each of these (which each have processors assigned) will write to 2 other positions in C, and so on.
\end{itemize}
Let us say that processor $p_i$ is assigned position $i$ in A and C.
\begin{lstlisting}
function Compose(A, B, C, P, lo, hi)
    if lo == hi then
        begin copy operation described above.
    else
        mid = (lo + hi) / 2
        Compose(A, B, C, {$p_i \in P$ | B[i] $\leq$ mid}, lo, mid)
        Compose(A, B, C, {$p_i \in P$ | B[i] > mid}, mid, hi)
\end{lstlisting}

\begin{centering}\textbf{BINARY TREE, number leaves -- O(lg(n)), n procs, EREW}\par\end{centering}
Eulerian tour via pointer doubling as in class, but leaves get '1' and other nodes get '0' when we do parallel prefix.

\begin{centering}\textbf{BINARY TREE, balance factor -- O(lg(n)), n procs, EREW}\par\end{centering}
Calculate height in O(lg(n)) time, using magic.

\begin{centering}\textbf{BINARY EXPRESSION TREE, evaluate -- O(lg$^2$(n)), n procs, CREW}\par\end{centering}
Use the class of functions $\frac{ax+b}{cx+d}$ and do evaluation as in class. Show this class is closed under desired ops.

\begin{centering}\textbf{BINARY BOOL EXPRESSION TREE, evaluate -- O(lg$^2$(n)), n procs, CREW}\par\end{centering}
At least one argument to every function is a constant--boolean expressions will not grow to unreasonable size, because each step can be simplified in constant time. Everything else is the same as in class.








\end{document}



\begin{centering}\textbf{Gas Station pt 1}\par\end{centering}
